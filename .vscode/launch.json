{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "blip-diffusion",
            "python": "/home/zzp/miniconda3/envs/llm-vision/bin/python",
            "type": "python",
            "request": "launch",
            "module": "torch.distributed.run",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/multimodal/LAVIS",
            "args": [
                "--nproc_per_node=1",
                "train.py",
                "--cfg-path",
                "lavis/projects/blip_diffusion/finetune-db-dog.yaml",
            ]
        },
        {
            "name": "imagereward",
            "type": "python",
            "request": "launch",
            "program": "src/make_dataset.py",
            "python": "/home/zzp/miniconda3/envs/ldm/bin/python",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/text2image/reward/train",
            "console": "integratedTerminal",
            // "args": [
            //     "launch", 
            //     "--mixed_precision=fp16", 
            //     "train_dreambooth_lora.py",
            //     "--pretrained_model_name_or_path=/mnt/f/aigc_data/model/stable-diffusion-v1-4/",
            //     "--instance_data_dir=dog",
            //     "--use_8bit_adam",
            //     "--class_data_dir=path-to-class-images",
            //     "--output_dir=path-to-save-model",
            //     "--with_prior_preservation", "--prior_loss_weight=1.0",
            //     "--instance_prompt=a photo of sks dog",
            //     "--class_prompt=a photo of dog",
            //     "--resolution=512",
            //     "--train_batch_size=1",
            //     "--sample_batch_size=1",
            //     "--gradient_accumulation_steps=1", "--gradient_checkpointing",
            //     "--learning_rate=5e-6",
            //     "--lr_scheduler=constant",
            //     "--lr_warmup_steps=0",
            //     "--num_class_images=200",
            //     "--max_train_steps=800",
            // ]
        },
        {
            "name": "imagereward-relf",
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/ldm/bin/accelerate",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/text2image/reward",
            "console": "integratedTerminal",
            "args": [
                "launch", 
                "--mixed_precision=fp16",
                "--num_processes=1", 
                "--mixed_precision=fp16",
                "refl.py",
                "--use_8bit_adam",
                "--resolution=512",
                "--center_crop", 
                "--random_flip",
                "--train_batch_size=1",
                "--gradient_accumulation_steps=4",
                "--gradient_checkpointing",
                "--max_train_steps=100",
                "--learning_rate=1e-05",
                "--max_grad_norm=1",
                "--lr_scheduler=constant", 
                "--lr_warmup_steps=0",
                "--output_dir=checkpoint/refl",
                "--grad_scale", "0.001",
                "--checkpointing_steps", "100"
            ]
        },
        {
            "name": "dreambooth",
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/ldm/bin/accelerate",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/text2image/diffusers/examples/dreambooth",
            "console": "integratedTerminal",
            "args": [
                "launch", 
                "--mixed_precision=fp16", 
                "train_dreambooth_lora.py",
                "--pretrained_model_name_or_path=/mnt/f/aigc_data/model/stable-diffusion-v1-4/",
                "--instance_data_dir=dog",
                "--use_8bit_adam",
                "--class_data_dir=path-to-class-images",
                "--output_dir=path-to-save-model",
                "--with_prior_preservation", "--prior_loss_weight=1.0",
                "--instance_prompt=a photo of sks dog",
                "--class_prompt=a photo of dog",
                "--resolution=512",
                "--train_batch_size=1",
                "--sample_batch_size=1",
                "--gradient_accumulation_steps=1", "--gradient_checkpointing",
                "--learning_rate=5e-6",
                "--lr_scheduler=constant",
                "--lr_warmup_steps=0",
                "--num_class_images=200",
                "--max_train_steps=800",
            ]
        },
        {
            "name": "controlnet",
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/ldm/bin/accelerate",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/text2image/diffusers/examples/controlnet",
            "console": "integratedTerminal",
            "args": [
                "launch", "train_controlnet.py",
                "--pretrained_model_name_or_path=/mnt/f/aigc_data/model/stable-diffusion-v1-4/",
                "--output_dir=./output",
                "--dataset_name=/mnt/f/aigc_data/data_set/fill50k",
                "--use_8bit_adam",
                "--resolution=512",
                "--validation_image", "./conditioning_image_1.png", "./conditioning_image_2.png",
                "--validation_prompt", "red circle with blue background", "cyan circle with brown floral background",
                "--train_batch_size=1",
                "--gradient_accumulation_steps=4",
                "--gradient_checkpointing",
                "--set_grads_to_none",
                "--mixed_precision", "fp16"
            ]
        },
        {
            "name": "ddpm-ddim",
            "type": "python",
            "request": "launch",
            "program": "scripts/image_train.py",
            "console": "integratedTerminal",
            "python": "/home/zzp/miniconda3/envs/ldm/bin/python",
            "env": {
                "MODEL_FLAGS": "--image_size 64 --num_channels 128 --num_res_blocks 3",
                "DIFFUSION_FLAGS": "--diffusion_steps 4000 --noise_schedule linear",
                "TRAIN_FLAGS": "--lr 1e-4 --batch_size 16"
            },
            "cwd": "/mnt/f/aigc/project/text2image/improved-diffusion",
            "justMyCode": true,
            "args": [
                "--data_dir", "datasets/cifar_train/",
                "--image_size", "64", "--num_channels", "128", "--num_res_blocks", "3",
                "--diffusion_steps", "4000", "--noise_schedule", "linear",
                "--lr", "1e-4", "--batch_size", "16"
            ]
        },
        {
            "name": "Dreambooth-Stable-Diffusion",
            "python": "/home/zzp/miniconda3/envs/ldm/bin/python",
            "type": "python",
            "request": "launch",
            "program": "scripts/stable_txt2img.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/text2image/Dreambooth-Stable-Diffusion",
            "args": [
                "--ddim_eta",
                "0.0",
                "--n_samples",
                "1",
                "--n_iter",
                "1",
                "--scale",
                "10.0",
                "--ddim_steps",
                "50",
                "--ckpt",
                "/mnt/f/aigc_data/model/sd-14-ckpt/sd-v1-4.ckpt",
                "--prompt",
                "a photo of a <class>",
            ]
        },
        {
            "name": "blip2-stage1",
            "env": {
                "python": "/home/zzp/miniconda3/envs/llm-vision/bin/python"
            },
            "type": "python",
            "request": "launch",
            "module": "torch.distributed.run",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/multimodal/LAVIS",
            "args": [
                "--nproc_per_node=1",
                "train.py",
                "--cfg-path",
                "lavis/projects/blip2/train/pretrain_stage1.yaml",
            ]
        },
        {
            "name": "blip2-stage2",
            "env": {
                "/home/zzp/miniconda3/envs/llm-vision/bin/python"
            },
            "type": "python",
            "request": "launch",
            "module": "torch.distributed.run",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/multimodal/LAVIS",
            "args": [
                "--nproc_per_node=1",
                "train.py",
                "--cfg-path",
                "lavis/projects/blip2/train/pretrain_stage2.yaml",
            ]
        },
        {
            "name": "lora-tuner",
            "env": {
                "/home/zzp/miniconda3/envs/llm/bin/python"
            },
            "type": "python",
            "request": "launch",
            "program": "tuner/train_lora.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/llm/LLMTuner",
            "args": [
                "--model_type",
                "llama",
                "--model_name_or_path",
                "/mnt/f/aigc_data/model/TinyLlama-1.1B-intermediate-step-955k-token-2T",
                "--target_modules",
                "q_proj,k_proj,v_proj,o_proj",
                "--data_path",
                "data/dummy.jsonl",
                "--output_dir",
                "dummy_output",
                "--max_length",
                "2048",
                "--use_flash_attn",
                "False",
                "--use_xformers_attn",
                "False",
                "--per_device_train_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "8",
                "--max_grad_norm",
                "1.0",
                "--learning_rate",
                "1e-4",
                "--weight_decay",
                "0.",
                "--num_train_epochs",
                "1",
                "--lr_scheduler_type",
                "cosine",
                "--warmup_ratio",
                "0.03",
                "--logging_steps",
                "5",
                "--save_strategy",
                "steps",
                "--save_steps",
                "10",
                "--save_total_limit",
                "1",
                "--bf16",
                "False",
                "--tf32",
                "False",
                "--report_to",
                "tensorboard",
                "--gradient_checkpointing",
                "True",
                "--optim",
                "paged_adamw_32bit",
                "--lora_r",
                "64",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.05",
                "--bits",
                "16",
                "--additional_trainable_params",
                "embed,norm"
            ]
        },
        {
            "name": "Debug DeepSpeed1",
            "env": {
                "/home/zzp/miniconda3/envs/llm/bin/python"
            },
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/llm/bin/deepspeed",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/llm/DeepSpeed-Chat/training/step1_supervised_finetuning",
            // "cwd": "/mnt/f/aigc/project/deepspeed/DeepSpeed-Chat/training/step2_reward_model_finetuning",
            // "cwd": "/mnt/f/aigc/project/deepspeed/DeepSpeed-Chat/training/step3_rlhf_finetuning",
            "console": "integratedTerminal",
            "args": [
                "--num_gpus",
                "1",
                "./main.py",
                "--model_name_or_path",
                "/mnt/f/aigc_data/model/facebook/opt-350m",
                "--data_path",
                "/mnt/f/aigc_data/data_set/rm-static",
                "--gradient_accumulation_steps",
                "8",
                "--lora_dim",
                "128",
                "--zero_stage",
                "0",
                "--enable_tensorboard",
                "--tensorboard_path",
                "./output",
                "--deepspeed",
                "--only_optimize_lora",
                "--output_dir",
                "./output",
                "--gradient_checkpointing",
                "--data_output_path",
                "/mnt/f/aigc_data/data_output_path",
            ]
        },
        {
            "name": "Debug DeepSpeed2",
            "env": {
                "/home/zzp/miniconda3/envs/llm/bin/python"
            },
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/llm/bin/deepspeed",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/llm/DeepSpeed-Chat/training/step2_reward_model_finetuning",
            // "cwd": "/mnt/f/aigc/project/deepspeed/DeepSpeed-Chat/training/step3_rlhf_finetuning",
            "console": "integratedTerminal",
            "args": [
                "--num_gpus",
                "1",
                "./main.py",
                "--model_name_or_path",
                "/mnt/f/aigc_data/model/facebook/opt-125m",
                "--data_path",
                "/mnt/f/aigc_data/data_set/rm-static",
                "--num_padding_at_beginning",
                "1",
                "--weight_decay",
                "0.1",
                "--dropout",
                "0.0",
                "--gradient_accumulation_steps",
                "4",
                "--lora_dim",
                "128",
                "--zero_stage",
                "0",
                "--enable_tensorboard",
                "--tensorboard_path",
                "./output",
                "--deepspeed",
                "--output_dir",
                "./output",
            ]
        },
        {
            "name": "Debug DeepSpeed3",
            "env": {
                "/home/zzp/miniconda3/envs/llm/bin/python"
            },
            "type": "python",
            "request": "launch",
            "program": "/home/zzp/miniconda3/envs/llm/bin/deepspeed",
            "justMyCode": true,
            "cwd": "/mnt/f/aigc/project/llm/DeepSpeed-Chat/training/step3_rlhf_finetuning",
            "console": "integratedTerminal",
            "args": [
                "--num_gpus",
                "1",
                "./main.py",
                "--data_path",
                "/mnt/f/aigc_data/data_set/rm-static",
                "--actor_model_name_or_path",
                "/mnt/f/aigc/project/llm/DeepSpeed-Chat/training/step1_supervised_finetuning/output",
                "--critic_model_name_or_path",
                "/mnt/f/aigc/project/llm/DeepSpeed-Chat/training/step2_reward_model_finetuning/output",
                "--actor_zero_stage",
                "0",
                "--critic_zero_stage",
                "0",
                "--num_padding_at_beginning",
                "1",
                "--gradient_accumulation_steps",
                "2",
                "--deepspeed",
                "--actor_lora_dim",
                "128",
                "--enable_hybrid_engine",
                "--actor_gradient_checkpointing",
                "--critic_gradient_checkpointing",
                "--actor_dropout",
                "0.0",
                "--output_dir",
                "./output",
            ]
        },
    ]
}